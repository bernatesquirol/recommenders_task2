{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD has 100000 ratings\n",
      "BD has 943 users\n",
      "BD has 1682 movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id         title movie_id  rating release_date sex  age\n",
       "0     196  Kolya (1996)      242       3  24-Jan-1997   M   49\n",
       "1     305  Kolya (1996)      242       5  24-Jan-1997   M   23\n",
       "2       6  Kolya (1996)      242       4  24-Jan-1997   M   42\n",
       "3     234  Kolya (1996)      242       4  24-Jan-1997   M   60\n",
       "4      63  Kolya (1996)      242       3  24-Jan-1997   M   31"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('data/ml-100k/u.user', sep='|', names=u_cols, dtype={'user_id':str})\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=r_cols, dtype={'movie_id':str, 'user_id':str})\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1', dtype={'movie_id':str})\n",
    "\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"BD has\", str(data.shape[0]),\"ratings\")\n",
    "print(\"BD has\",data.user_id.nunique(),\"users\")\n",
    "print(\"BD has\",data.movie_id.nunique(),\"movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79619, 8)\n",
      "(20381, 8)\n",
      "Int64Index([], dtype='int64')\n",
      "Training data_set has 79619 ratings\n",
      "Test data set has 20381 ratings\n",
      "La BD has 1682 movies\n"
     ]
    }
   ],
   "source": [
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "data_train = data[grouped.for_testing == False]\n",
    "data_test = data[grouped.for_testing == True]\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "print(data_train.index & data_test.index)\n",
    "\n",
    "print(\"Training data_set has\", str(data_train.shape[0]),\"ratings\")\n",
    "print(\"Test data set has\", str(data_test.shape[0]),\"ratings\")\n",
    "print(\"La BD has\", data.movie_id.nunique(), \"movies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_pickle('data/data_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_pickle('data/data_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to get the set of movies from user with id  \"1\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_db(ratings, adjust_users=False):\n",
    "    ratings_pivoted = ratings.pivot(\n",
    "        index='movie_id',\n",
    "        columns='user_id',\n",
    "        values='rating'\n",
    "    )\n",
    "    if adjust_users:\n",
    "        ratings_pivoted = ratings_pivoted.apply(lambda u: u-u.mean(), axis=0)\n",
    "    ratings_pivoted['users_rated']=ratings_pivoted.apply(lambda m: m[-m.isnull()].index, axis=1)    \n",
    "    return ratings_pivoted#.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = data_train_pivoted['users_rated'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_euclid(a,b):\n",
    "    from scipy.spatial.distance import euclidean\n",
    "    return 1.0/(1.0+euclidean(a,b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(a,b):\n",
    "    from scipy.spatial.distance import correlation\n",
    "    return 1-correlation(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cosine(a,b):\n",
    "    from scipy.spatial.distance import cosine\n",
    "    return 1-cosine(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(pivoted_m1, pivoted_m2, similarity):\n",
    "#     m1 = df.loc[m_id1]\n",
    "#     m2 = df.loc[m_id2]\n",
    "    if (len(pivoted_m1)==0 or len(pivoted_m2)==0):\n",
    "        return 1\n",
    "    users_1 = pivoted_m1['users_rated']\n",
    "    users_2 = pivoted_m2['users_rated']\n",
    "    intersection = users_1[users_1.isin(users_2)]\n",
    "    if len(intersection)==0: \n",
    "        return 1\n",
    "    return similarity(pivoted_m1.loc[intersection], pivoted_m2.loc[intersection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeItemReco:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"    \n",
    "    def __init__(self, ratings, similarity, adjust_users=False, k=None, sim_matrix_path=None):\n",
    "        \"\"\" Constructor \"\"\"        \n",
    "        self.df = pivot_db(ratings, adjust_users)        \n",
    "        self.similarity=similarity\n",
    "        if not sim_matrix_path:\n",
    "            self.sim_matrix = pd.DataFrame(1, columns=self.df.index, index=self.df.index)\n",
    "        else:\n",
    "            self.sim_matrix = pd.read_pickle(sim_matrix_path)\n",
    "        self.k = k+1 if k else len(self.df.index)\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for users \"\"\"\n",
    "        for i, mId1 in enumerate(tqdm(self.df.index)):\n",
    "            for j, mId2 in enumerate(self.df.index[i+1:]):\n",
    "                sim = compare(self.df.loc[mId1],self.df.loc[mId2], self.similarity)\n",
    "                self.sim_matrix.loc[mId1,mId2]=sim\n",
    "                self.sim_matrix.loc[mId2,mId1]=sim\n",
    "                \n",
    "    def estimate_basic(self, u, j):\n",
    "        # u is user\n",
    "        # j is movie\n",
    "        if u not in self.df:\n",
    "            print('u_{} not in training'.format(u))\n",
    "            return 3\n",
    "        if j not in self.sim_matrix:\n",
    "            print('m_{} not in training'.format(j))\n",
    "            return 3\n",
    "        u_ratings = self.df[u][self.df[u]>0]\n",
    "        num=0\n",
    "        den=0\n",
    "        P_k = self.sim_matrix[j].loc[u_ratings.index].sort_values(ascending=False).iloc[1:self.k]\n",
    "        means_movies = self.df.apply(lambda m: m.loc[m['users_rated']].mean(),axis=1)\n",
    "        for i, sim in P_k.iteritems():\n",
    "            num+=sim*u_ratings[i]\n",
    "            den+=sim\n",
    "        if den==0: \n",
    "            if means_movies[j]>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return means_movies[j]\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return u_ratings.mean()\n",
    "        return num/den\n",
    "    \n",
    "    def estimate_mean(self, u, j):\n",
    "        # u is user\n",
    "        # j is movie\n",
    "        if u not in self.df:\n",
    "            print('u_{} not in training'.format(u))\n",
    "            return 3\n",
    "        if j not in self.sim_matrix:\n",
    "            print('m_{} not in training'.format(j))\n",
    "            return 3\n",
    "        u_ratings = self.df[u][self.df[u]>0]\n",
    "        num=0\n",
    "        den=0\n",
    "        P_k = self.sim_matrix[j].loc[u_ratings.index].sort_values(ascending=False).iloc[1:]\n",
    "        means_movies = self.df.apply(lambda m: m.loc[m['users_rated']].mean(),axis=1)\n",
    "        for i, sim in P_k.iteritems():\n",
    "            r_i_mean = means_movies[i]\n",
    "            num+=sim*(u_ratings[i]-r_i_mean)\n",
    "            den+=sim\n",
    "        if den==0: \n",
    "            if means_movies[j]>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return means_movies[j]\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return u_ratings.mean()\n",
    "        return means_movies[j]+num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_sample = data_train[data_train.movie_id.apply(lambda x: int(x)<100)]\n",
    "# data_test_sample = data_test[data_test.movie_id.apply(lambda x: int(x)<100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# item_cosine_sample = CollaborativeItemReco(data_train_sample, sim_cosine)\n",
    "# item_cosine_sample.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data_test[data_test.movie_id.apply(lambda x: int(x)<100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cosine = CollaborativeItemReco(data_train, sim_cosine, sim_matrix_path='data/cosine.pkl')\n",
    "# item_cosine.learn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_cosine.sim_matrix.to_pickle('data/cosine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cosine_adjusted = CollaborativeItemReco(data_train, sim_cosine, adjust_users=True, sim_matrix_path='data/cosine_adjusted.pkl')\n",
    "# item_cosine_adjusted.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_cosine_adjusted.sim_matrix.to_pickle('cosine_adjusted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_pearson = CollaborativeItemReco(data_train, sim_pearson, sim_matrix_path='data/pearson.pkl')\n",
    "# item_pearson.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_pearson.sim_matrix.to_pickle('data/pearson.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_pearson_adjusted = CollaborativeItemReco(data_train, sim_pearson, adjust_users=True, sim_matrix_path='pearson_adjusted.pkl')\n",
    "# item_pearson_adjusted.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_pearson_adjusted.sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_pearson_adjusted.sim_matrix.to_pickle('data/pearson_adjusted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_euclid = CollaborativeItemReco(data_train, sim_euclid, sim_matrix_path='data/euclid.pkl')\n",
    "# item_euclid.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_euclid.sim_matrix.to_pickle('data/euclid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(estimate_f,data_train,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    u_train = set(data_train.user_id)\n",
    "    m_train = set(data_train.movie_id)\n",
    "    estimated = np.array([estimate_f(u,i) for (u,i) in zip(data_test.user_id, data_test.movie_id)])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tqdm' from 'C:\\\\Users\\\\annae\\\\miniconda3\\\\lib\\\\site-packages\\\\tqdm\\\\__init__.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# import tqdm\n",
    "# importlib.reload(tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {'cosine':item_cosine, 'pearson':item_pearson, 'euclid':item_euclid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model.estimate_basic, data_train, data_test.sample(1))\n",
    "data_small_test = data_test.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- cosine ---------\n",
      "RMSE basic of cosine: 1.0366071543385287\n",
      "RMSE mean of cosine: 0.9285720967063059\n",
      "--------- pearson ---------\n",
      "RMSE basic of pearson: 4.378503532488526\n",
      "RMSE mean of pearson: 4.535351302983304\n",
      "--------- euclid ---------\n",
      "RMSE basic of euclid: 0.9879176904758223\n",
      "RMSE mean of euclid: 0.9013302016495014\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "for model_label, model in all_models.items():\n",
    "    model.sim_matrix = model.sim_matrix.fillna(0)\n",
    "    print('--------- {} ---------'.format(model_label))\n",
    "    rmse.append(evaluate(model.estimate_basic, data_train, data_small_test))\n",
    "    print('RMSE basic of {}: {}'.format(model_label,rmse[-1]))\n",
    "    rmse.append(evaluate(model.estimate_mean, data_train, data_small_test))\n",
    "    print('RMSE mean of {}: {}'.format(model_label,rmse[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(estimate_f, data_train, data_test, N=25):\n",
    "    all_movies_ids = set(data_train.movie_id.values).union(set(data_train.movie_id.values))\n",
    "    in_top = 0\n",
    "    ratings_5_test = data_test[data_test.rating==5]\n",
    "#     print(len(ratings_5_test))\n",
    "    for i, row in ratings_5_test.iterrows():\n",
    "        user_seen = list(data_train[data_train.user_id==row.user_id].movie_id.values)+list(data_test[data_test.user_id==row.user_id].movie_id.values)\n",
    "        unseen = all_movies_ids.difference(user_seen)\n",
    "        choosen_unseen = np.random.choice(list(unseen), min(len(unseen), 50), replace=False)\n",
    "#         print(i, len(choosen_unseen))\n",
    "        ranked_random = pd.Series(list(map(lambda i:estimate_f(u=row.user_id,j=i),choosen_unseen))+[estimate_f(row.user_id, row.movie_id)],index=list(choosen_unseen)+[row.movie_id])\n",
    "        index_row = np.argwhere(ranked_random.sort_values(ascending=False).index.values==row.movie_id).flatten()[0]\n",
    "        if index_row<15:\n",
    "            in_top+=1\n",
    "    return in_top/len(ratings_5_test)\n",
    "#     print(row.user_id)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- cosine ---------\n",
      "P/R basic of cosine: 0.423728813559322\n",
      "P/R mean of cosine: 0.7584745762711864\n",
      "--------- pearson ---------\n",
      "P/R basic of pearson: 0.8559322033898306\n",
      "P/R mean of pearson: 0.9279661016949152\n",
      "--------- euclid ---------\n",
      "P/R basic of euclid: 0.6991525423728814\n",
      "P/R mean of euclid: 0.8177966101694916\n"
     ]
    }
   ],
   "source": [
    "prs = []\n",
    "for model_label, model in all_models.items():\n",
    "    print('--------- {} ---------'.format(model_label))\n",
    "    prs.append(precision_recall(model.estimate_basic, data_train, data_small_test))\n",
    "    print('P/R basic of {}: {}'.format(model_label,prs[i]))\n",
    "    prs.append(precision_recall(model.estimate_mean, data_train, data_small_test))\n",
    "    print('P/R mean of {}: {}'.format(model_label,prs[i+1]))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
